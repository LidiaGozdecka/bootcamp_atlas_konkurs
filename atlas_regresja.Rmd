---
title: "trying_sth_with_python"
author: "Dominika Zydorczyk"
date: "2024-11-15"
output: html_document
---

```{r}
library(tidyverse)
library(rio)
Data_atlas <- import("data_atlas.csv")

```

Przeglądanie zawartości kolumn
```{r}
unique(Data_atlas$overdue_payments) #pomyslec jak to lepiej zapisac bo są wyniki:"brak opóźnień" "" "opóźnienia" "3" "2" "4" 
unique(Data_atlas$credit_history) #dobra/brak, nie ma zlej historii
unique(Data_atlas$employment_type)#4 typy "samozatrudnienie" "stała" "brak" "określona" 
unique(Data_atlas$owns_property) #tak/nie
unique(Data_atlas$education) #3 kategorie "wyższe" "średnie" "podstawowe"
unique(Data_atlas$city) #3 kategorie "małe" "średnie" "duże" 
unique(Data_atlas$marital_status) #3 kategorie, mozna jakos skrocic ewentualnie
```

 
Czyszczenie
```{r}
Data_atlas <- Data_atlas[ ,-1] #usuwanie pierwszej kolumny z indeksami

Data_atlas$income <- gsub("[^0-9]", "", Data_atlas$income)
Data_atlas$income <- as.numeric(Data_atlas$income)

Data_atlas$children <- ifelse(Data_atlas$children == "brak", 0, Data_atlas$children)#brak dzieci = 0 dzieci
Data_atlas$children <- gsub("[^0-9]", "", Data_atlas$children)
Data_atlas$children <- as.numeric(Data_atlas$children)

Data_atlas$assets_value <- gsub("[^0-9]", "", Data_atlas$assets_value)
Data_atlas$assets_value <- as.numeric(Data_atlas$assets_value)

Data_atlas[c("credit_history", "overdue_payments", "employment_type", "owns_property", "education", "city", "marital_status")] <- lapply(Data_atlas[c("credit_history", "overdue_payments", "employment_type", "owns_property", "education", "city", "marital_status")], as.factor)

```

```{r}
Data_atlas$credit_history <- gsub("^\\s*$", "brak", Data_atlas$credit_history)
Data_atlas$credit_history <- gsub("brak historii", "brak", Data_atlas$credit_history)
Data_atlas$credit_history <- gsub("dobra historia", "dobra", Data_atlas$credit_history)

#M,S,D  - married, single, divorced
Data_atlas$marital_status <- gsub("żonaty/zamężna", "M", Data_atlas$marital_status)
Data_atlas$marital_status <- gsub("kawaler/panna", "S", Data_atlas$marital_status)
Data_atlas$marital_status <- gsub("rozwiedziony/rozwiedziona", "D", Data_atlas$marital_status)

# puste assets value ustawiam na 0
Data_atlas <- Data_atlas %>%
  mutate(assets_value = replace(assets_value, is.na(assets_value), 0))

#puste ustawiam jako brak nieruchomosci
Data_atlas$owns_property <- gsub("^\\s*$", "nie", Data_atlas$owns_property)

```

```{r}
library(reticulate)
virtualenv_install("r-reticulate", packages = c("pandas", "scikit-learn", "xgboost", "matplotlib", "seaborn", "imblearn"))

```

```{python}
# Potrzebne biblioteki
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from xgboost import XGBRegressor
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from imblearn.metrics import specificity_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
```

```{r}
Data_rl <- import("data_atlas_clean.csv")
py$Data_rl <- Data_rl
```

Czy kolumna employment_type ma sens porządkowy?
Kategorie mogą sugerować pewien porządek w kontekście stabilności finansowej:
Stała (największa stabilność),
Określona (średnia stabilność, zakładając że określona oznacza zatrudnienie na określony czas),
Samozatrudnienie (zależne od branży, ale generalnie może być mniej stabilne niż zatrudnienie na etacie),
Brak (najmniejsza stabilność, brak dochodów).

W związku z tym możliwe, że istnieje pewien porządek, który może wskazywać na różny wpływ na zdolność kredytową. Jednak aby uniknąć błędnych założeń o proporcjonalności, zastosuję kodowanie binarne. Podobnie z overdue_payments, credit_history, owns_property, education, city, marital_status.

```{python}
Data_rl = pd.get_dummies(Data_rl, columns = ['overdue_payments', 'credit_history', 'employment_type', 'owns_property', 'education', 'city', 'marital_status'])
```

```{r}
Data_rl <- py$Data_rl
```


Regresja liniowa przewiduje wartości ciągłe, które mogą znajdować się poza zakresem [0, 1].
W przypadku zmiennej wynikowej klasyfikacyjnej (w naszym przypadku 0 lub 1), model regresji liniowej może zwrócić wartości spoza tego zakresu, np. -0.5 lub 1.5, co nie ma sensu w kontekście klasyfikacji, co widać poniżej. 
```{python}
# X - zmienne niezależne (predyktory), y - zmienna zależna (wynikowa)
X = Data_rl.drop('credit_risk', axis=1)
y = Data_rl['credit_risk']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

lr_model = LinearRegression()

lr_model.fit(X_train, y_train)

y_pred_lr = lr_model.predict(X_test)

```

```{python}
# Oceniamy model
mse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))  # Błąd średniokwadratowy
r2_lr = r2_score(y_test, y_pred_lr)  # Współczynnik determinacji R^2
mae_lr = mean_absolute_error(y_test, y_pred_lr) #Średni błąd bezwzględny
```


```{r}
Data_rl <- py$Data_rl

# Ładowanie danych z Pythona
y_pred_lr_r <- py$y_pred_lr  # Zmienna 'y_pred_lr' z Pythona
mse_lr_r <- py$mse_lr  # Zmienna 'mse' z Pythona
r2_lr_r <- py$r2_lr # Zmienna 'r2' z Pythona
mae_lr_r <- py$mae_lr

# Wyświetlanie wyników
print("Predykcje:")
print(y_pred_lr_r)

print("EMSE:")
print(mse_lr_r)

print("R2 Score:")
print(r2_lr_r)

print("MAE Score:")
print(mae_lr_r)

```

Dla problemu klasyfikacyjnego można zastosować model regresji logistycznej, jednak  nie radzi on sobie dobrze ze złożonymi relacjami. W związku z tym zastosowane zostaną modele takie jak XGBoost, Drzewo Decyzyjne, Las Losowy, naiwny klasyfikator Bayesa i SVM.


```{r}
py$Data_rl <- Data_rl
```



```{python}
# X - zmienne niezależne (predyktory), y - zmienna zależna (wynikowa)
X = Data_rl.drop('credit_risk', axis=1)
y = Data_rl['credit_risk']

# Dzielimy zbiór na uczący i testowy
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

```


XGBoost
```{r}
py$Data_rl <- Data_rl
```


```{python}
# Tworzymy model XGBoost
xgbc_model = XGBClassifier()

xgbc_model.fit(X_train, y_train)

y_pred_xgbc = xgbc_model.predict(X_test)

#ocenianie modelu
acc_xgbc = accuracy_score(y_test, y_pred_xgbc)
recall_xgbc = recall_score(y_test, y_pred_xgbc)
spec_xgbc = specificity_score(y_test, y_pred_xgbc)
```


```{r}
Data_rl <- py$Data_rl

# Ładowanie danych z Pythona
y_pred_xgbc_r <- py$y_pred_xgbc  # Zmienna 'y_pred_lr' z Pythona

acc_xgbc_r <- py$acc_xgbc
recall_xgbc_r <- py$recall_xgbc 
spec_xgbc_r <- py$spec_xgbc

# Wyświetlanie wyników
#print("Predykcje:")
#print(y_pred_xgbr_r)

print(acc_xgbc_r)
print(recall_xgbc_r)
print(spec_xgbc_r)

```


Drzewo decyzyjne
```{r}
py$Data_rl <- Data_rl
```


```{python}
# Tworzymy model Dzrewa decyzyjnego
dt_model = DecisionTreeClassifier(max_depth=4, min_samples_leaf=10, random_state=42)

dt_model.fit(X_train, y_train)

y_pred_dt = dt_model.predict(X_test)

#wizualizacja drzewa
plt.figure(figsize=(20,10))
plot_tree(dt_model, filled=True, feature_names=X_train.columns, fontsize=10)
plt.show()

#ocenianie modelu
acc_dt = accuracy_score(y_test, y_pred_dt)
recall_dt = recall_score(y_test, y_pred_dt)
spec_dt = specificity_score(y_test, y_pred_dt)
```


```{r}
Data_rl <- py$Data_rl

# Ładowanie danych z Pythona
y_pred_dt <- py$y_pred_dt  # Zmienna 'y_pred_lr' z Pythona

acc_dt_r <-  py$acc_dt
recall_dt_r <- py$recall_dt
spec_dt_r <-  py$spec_dt

# Wyświetlanie wyników
print("Predykcje:")
print(y_pred_dt)

print(acc_dt_r)
print(recall_dt_r)
print(spec_dt_r)
```

```{r}
py$Data_rl <- Data_rl
```


Las losowy
```{python}
# Tworzymy model Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Trenujemy model na danych treningowych
rf_model.fit(X_train, y_train)

# Przewidujemy wyniki na zbiorze testowym
y_pred_rf = rf_model.predict(X_test)

# Ocena modelu
acc_rf = accuracy_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)
spec_rf = specificity_score(y_test, y_pred_rf)
```



```{r}
Data_rl <- py$Data_rl

y_pred_rf_r <- py$y_pred_rf
acc_rf_r <- py$acc_rf
recall_rf_r <- py$recall_rf
spec_rf_r <- py$spec_rf

print(acc_rf_r)
print(recall_rf_r)
print(spec_rf_r)
```


```{r}
py$Data_rl <- Data_rl
```

Naiwny klasyfikator Bayesa
```{python}
nb_model = GaussianNB()

nb_model.fit(X_train, y_train)

y_pred_nb = nb_model.predict(X_test)

#Ocena modelu
acc_nb = accuracy_score(y_test, y_pred_nb)
recall_nb = recall_score(y_test, y_pred_nb)
spec_nb = specificity_score(y_test, y_pred_nb)
```

```{r}
Data_rl <- py$Data_rl

y_pred_nb_r <- py$y_pred_nb

acc_nb_r <- py$acc_nb
recall_nb_r <- py$recall_nb
spec_nb_r <- py$spec_nb

print(acc_nb_r)
print(recall_nb_r)
print(spec_nb_r)

```


```{r}
py$Data_rl <- Data_rl
```

```{python}
# Funkcja, przyjmująca jako argumenty rzeczywiste wartości zbioru testowego i wartości, które przewidział model

def cl_metrics(y_true, y_pred):
  accuracy = round(accuracy_score(y_true, y_pred),4)
  recall = round(recall_score(y_true, y_pred),4)
  specificity = round(specificity_score(y_true, y_pred),4)
  return accuracy, recall, specificity

# słownik
cl_models = {'XGB': y_pred_xgbc,
             'DT': y_pred_dt,
             'RF': y_pred_rf,
             'NB': y_pred_nb
             }
            
results = []

# Obliczanie metryk dla wszystkich modeli (elementów słownika) i dopisanie wyników do listy

for model, y_pred in cl_models.items():
  accuracy, recall, specificity = cl_metrics(y_test, y_pred)
  results.append({
    'Model': model,
    'Accuracy': accuracy,
    'Recall': recall,
    'Specificity': specificity
  })
  
pd.DataFrame(results)
```

```{python}
# Funkcja jako argumenty przyjmuje wartości rzeczywiste, wartości przewidywane przez model oraz tytuł

def plot_confmat(y_test, y_pred, title):

  # tablica pomyłek
  cm = confusion_matrix(y_test, y_pred)
  
  # macierz pomylek
  cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm)
  cm_disp.plot(cmap = plt.cm.Blues)
  plt.title(title)
  plt.show()
  
# wwywołanie funkcję dla każdego z modeli
for model, y_pred in cl_models.items():
  plot_confmat(y_test, y_pred, title=f'Confusion Matrix for {model}')
```


